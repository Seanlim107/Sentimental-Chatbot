data:
  max_seq: 10
  train_size: 0.8
  batch_size: 16

model:
  embedding_dim: 128
  lstm_hidden_dim: 128
  hidden_dim: 128
  hidden_dim2: 64
  n_layers: 1
  drop_prob: 0.5
  
train:
    epochs: 40
    learning_rate: 0.01
